{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayes' theorem\n",
    "\n",
    "Bayesheorem is a formala that describes how to update the probabilities of hypotheses when given evidence.\n",
    "\n",
    "Given a hypothesis $\\theta$ and evidence $x$, Bayes' theorem states that the relationship between the propability of the hypothesis before getting the evidence $P(\\theta)$ and the probability of hypothesis after getting the evidence $P(\\theta | x)$ is:\n",
    "\n",
    "\\begin{equation}\n",
    "P(\\theta|x)=\\frac{P(\\theta \\cap x)}{P(x)}=\\frac{P(x|\\theta)Â· P(\\theta)}{P(x)}\n",
    "\\end{equation}\n",
    "\n",
    "Here we use $P(x|\\theta)$ as the likelihood, $P(\\theta)$ is the prior, that is the probability that appear $\\theta$ in the model and $P(x)$ is the evidence, the probobility of observing the datas given the true model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#librerias a usar \n",
    "import matplotlib. pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import scipy\n",
    "import scipy.special\n",
    "import math\n",
    "from scipy.optimize import minimize\n",
    "import scipy.optimize as op\n",
    "import scipy.stats as stats\n",
    "import time\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arrangement of the data to work with them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#datos:\n",
    "tb1=np.loadtxt('jla_mub_covmatrix.dat')\n",
    "tb2=np.loadtxt('jla_mub.txt')\n",
    "\n",
    "# divido los datos de jla_mub.txt en dos arrelgos z y mu \n",
    "z=tb2[:,0]\n",
    "mu=tb2[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#arreglo los datos de jla_mud_covmatrix.dat en una matriz de 31x31\n",
    "covmatrix=[]\n",
    "for i in range(31):\n",
    "    row=[]\n",
    "    for j in range(31):\n",
    "        row.append(tb1[(31*i)+j])\n",
    "    covmatrix.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pongo las varianzas de la matriz anterior (que se encuentran en la diagunal) en un arreglo.  \n",
    "var=[]\n",
    "for i in range(31):\n",
    "    var.append(covmatrix[i][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Equations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sss(omg):\n",
    "    return pow((1-omg)/omg,(1/3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eta(a,omg):\n",
    "    r=np.sqrt(pow(sss(omg),3)+1)\n",
    "    return 2*r*pow((pow(a,-4)-(0.1540*sss(omg)*pow(a,-3))+(0.4304*pow(sss(omg),2)*pow(a,-2))+(0.19097*pow(sss(omg),3)*pow(a,-1))+(0.066941*pow(sss(omg),4))),-1/8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def D_L(z,omg,H):\n",
    "    return (299792.458/H)*(1+z)*(eta(1,omg)-eta((1/(1+z)),omg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mud(z,omg,H):\n",
    "    return 25+(5*np.log10(D_L(z,omg,H)))-(5*np.log10(H/100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for the maximum likelihood estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lnlik (datos, P_ini):\n",
    "    #Likelihood con Parametrso iniciales.\n",
    "    omg0= P_ini[2]\n",
    "    H0= P_ini[0] \n",
    "    z=datos[0]\n",
    "    mu=datos[1]\n",
    "    var=datos[2]\n",
    "    return np.sum(-0.5*np.divide(pow((mu-mud(z,omg0,H0)),2),var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_ini = [70,2,0.5,0.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MCMC (datos,P_ini):\n",
    "    fp=open('Tabla_datos(2).dat',\"w\")\n",
    "    \n",
    "    #Parametros iniciales.\n",
    "    omg0= P_ini[2] #0.4\n",
    "    H0= P_ini[0] #70.0\n",
    "    sigma1= P_ini[3] #0.05\n",
    "    sigma2= P_ini[1] #2\n",
    "    \n",
    "    #Likliehood con nuevos doatos.\n",
    "    for i in range(10000): \n",
    "        omg = np.random.normal(P_ini[2],P_ini[3])\n",
    "        H = np.random.normal(P_ini[0],P_ini[1])\n",
    "        P_ini2 = np.array([H,P_ini[1],omg,P_ini[3]])\n",
    "        if omg>0 and H>0:\n",
    "            \n",
    "            if lnlik(datos, P_ini2) > lnlik(datos, P_ini):\n",
    "                P_ini=P_ini2\n",
    "                fp.write(\"%f  \\t%f \\n\" % (P_ini[0],P_ini[2]))\n",
    "            else:\n",
    "                pro=random.randrange(1,100000000)/100000000\n",
    "                diff=lnlik2(datos, P_ini2)-lnlik2(datos, P_ini)\n",
    "                if diff>np.log(pro):\n",
    "                    P_ini=P_ini2\n",
    "                    fp.write(\"%f  \\t%f \\n\" % (P_ini[0],P_ini[2]))\n",
    "    fp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Marginalization & uncertainty estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lnprior(P_ini):\n",
    "    H = P_ini[0]\n",
    "    omg = P_ini[2]\n",
    "    if 0 < H < 1 and 50 < omg < 100 :\n",
    "        return 0.0\n",
    "    return -np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lnprob(datos,P_ini):\n",
    "    lp = lnprior(P_ini)\n",
    "    if not np.isfinite(lp):\n",
    "        return -np.inf\n",
    "    return lp + lnlik(datos,P_ini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndim, nwalkers = 3, 100\n",
    "#pos = [result[\"x\"] + 1e-4*np.random.randn(ndim) for i in range(nwalkers)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'emcee'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-538a1b840aad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0memcee\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#sampler = emcee.EnsembleSampler(nwalkers, ndim, lnprob, args=(datos, P_ini))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'emcee'"
     ]
    }
   ],
   "source": [
    "import emcee\n",
    "#sampler = emcee.EnsembleSampler(nwalkers, ndim, lnprob, args=(datos, P_ini))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
